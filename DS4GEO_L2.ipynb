{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS4GEO_L2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyMG+QfLElURGEtSVOG8ZsBp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds4geo/ds4geo/blob/master/DS4GEO_L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yfRRs6n8q0",
        "colab_type": "text"
      },
      "source": [
        "# **Data Science for Geoscientists - Winter Semester 2020**\n",
        "# **Session 2**\n",
        "\n",
        "In the previous session, we handled data in a very simple way using pandas. In this session we will introduce a few other helpful python object types for handling data, and expecially learn how to index/slice data (extract only certain parts of the data/object). Specifically, we will cover lists, dictionaries, and arrays from the numpy library.\n",
        "\n",
        "We will also introduce simple array operations and aggregations, then apply these topics to a worked example from the geosciences.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QMoY59BoZBt",
        "colab_type": "text"
      },
      "source": [
        "# Section 1 - Lists, Dictionaries and Indexing\n",
        "\n",
        "Lists and dictionaries are built-in python objects useful for storing and handling data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUvoXMscfpfj",
        "colab_type": "text"
      },
      "source": [
        "# Lists\n",
        "Python lists are ordered collections of other python objects, separated by commas. They are defined by square brackets [ ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RsAroYgmrqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = [1,2,3] # List of integers\n",
        "print(\"a:\", a)\n",
        "\n",
        "b = [1.5, 2.5, 3.5] # List of floats\n",
        "print(\"b:\", b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA3ekiYUgY8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lists can contain different types\n",
        "c = [1, \"data\", 2.5]\n",
        "print(\"b:\", b)\n",
        "\n",
        "# Including other lists (nested)\n",
        "d = [[1,2,3], [4,5,6]]\n",
        "print(\"d:\", d)\n",
        "\n",
        "e = [a, b]\n",
        "print(\"e:\", e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzjXALvu71A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# They can contain any other python objects\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "f = [pd, np, plt] # But there's no reason to actually do this\n",
        "print(\"f:\", f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEnPisV-8UT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From last week, you'll recall dir() can be used to find methods on objects\n",
        "a = [1, 2, 3]\n",
        "# Append adds a new item to the end of a list\n",
        "a.append(4)\n",
        "print(\"a:\", a)\n",
        "\n",
        "# Extend joins to lists *in place*\n",
        "a.extend(b) # notice we don't assign a result\n",
        "print(\"a:\", a)\n",
        "# + operator when applied to two lists but not *in place*:\n",
        "h = a + b\n",
        "print(\"h:\", h)\n",
        "\n",
        "# sort does what it suggests, in place\n",
        "a.sort()\n",
        "print(\"a:\", a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKvxYMn-8JD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tuples are another type very similar to lists except they can't be modified\n",
        "# i.e. you cannot append to a tuple\n",
        "# They are defined by parentheses ( ) instead of [ ]\n",
        "a_tuple = (1, 2, 3)\n",
        "print(\"a_tuple:\", a_tuple)\n",
        "\n",
        "# The specific reasons for using tuples complex.\n",
        "# You will see them in documentation, but usually you can just use a list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKya8c8A-KeZ",
        "colab_type": "text"
      },
      "source": [
        "# Dictionaries\n",
        "Python dictionaries are un-ordered collections of pairs known as keys and values. They function like language dictionaries where you look up a word (they key) and see its definition or translation (value).\n",
        "They are defined with braces { }, separated by commas, and colons : indicate the key-value relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzjLEC7z-96o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a simple German to English language dictionary\n",
        "De2En = {\"Bier\": \"Beer\", \"Wurst\": \"Sausage\"}\n",
        "\n",
        "# When making lists and dictionaries, you can wrap between lines for readability:\n",
        "De2En = {\"Bier\": \"Beer\",\n",
        "         \"Wurst\": \"Sausage\",\n",
        "         \"Kren\": \"Horseradish\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWQ6DiUmXfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Values can be any python object, e.g. lists:\n",
        "rocks = {\"igneous\": [\"Granite\", \"Basalt\", \"Rhyolite\"],\n",
        "         \"Sedimentary\": [\"Sandstone\", \"Limestone\"]}\n",
        "\n",
        "# Keys can be some python objects (int, float, string, tuple), but not others (lists or dicts)\n",
        "# Keys and values do not all have to be the same type\n",
        "complex_dict = {0: \"zero\",\n",
        "                \"one point 5\": 1.5,\n",
        "                2.5: [\"two\", \"point\", \"five\"]}\n",
        "\n",
        "# Dictionaries can also be nested like lists.\n",
        "# Note the nesting is multi-line and aligned to improve readability\n",
        "rock_dict = {\"granite\": {\"type\": \"igneous\",\n",
        "                         \"composition\": {\"quartz\": 0.5,\n",
        "                                         \"feldspar\": 0.2},\n",
        "                         \"locations\": [(50.59671,-3.98289),\n",
        "                                       (50.59591,-4.61987)]},\n",
        "             \"sandstone\": {}}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8WSM2Z7_Mq0",
        "colab_type": "text"
      },
      "source": [
        "# List and Dictionary Indexing\n",
        "You can select objects/data from lists and dictionaries using square brackets [ ].\n",
        "List indexing is based on numeric positions, while dictionary indexing is based on its keys.\n",
        "\n",
        "**Note** python positional indexing (for lists, numpy, pandas, etc) always starts at 0. i.e. the first item is 0. This might seem counter intuitive at first, but when combined with some other features of python, it actually simplifies code in many situations!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktp65NaU_hFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remind ourselves what is in variable \"c\"\n",
        "print(c)\n",
        "\n",
        "# Print positions 0, 1 and 2 of list \"c\"\n",
        "print(c[0])\n",
        "print(c[1])\n",
        "print(c[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUl0Hm56swWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If we try to index a position beyond the size of the list, we get an index error\n",
        "# Uncomment this line to try it.\n",
        "# (It is commented out so you can run all the code in this notebook without generating an error)\n",
        "#print(c[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPKTGv5gs9Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List indexing also works with negative numbers in reverse, with -1 being the last index\n",
        "print(c)\n",
        "print(c[-1]) # the last item in c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pQdDsxdtAVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With nested objects, indexing can be stacked with sets of square brackets [ ][ ]\n",
        "print(d)\n",
        "print(d[1])\n",
        "print(d[1][2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6LzIarTuicP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Indexing tuples and strings works exactly the same way\n",
        "print(a_tuple)\n",
        "print(a_tuple[0])\n",
        "\n",
        "print(c)\n",
        "print(c[1])\n",
        "print(c[1][2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcox6VdWuw4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For lists, tuples and strings (and numpy - see later), ranges also work.\n",
        "# Ranges are \"half-open\", i.e. include the first index, but not the last.\n",
        "# This is so when you use a range of e.g. 2:4, you get a result of length 2, despite indexing starting at 0\n",
        "print(a)\n",
        "print(a[2:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoHF-i6ExPp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Also useful is finding the length of lists, dicts and strings:\n",
        "print(\"length of list a:\", len(a))\n",
        "print(\"length of dict rocks:\", len(rocks))\n",
        "print(\"length of string in position 1 of list c:\", len(c[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0XESPXRypsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionaries are indexed by their keys:\n",
        "print(De2En[\"Bier\"])\n",
        "\n",
        "# And example of indexing nested objects\n",
        "print(rocks[\"igneous\"])\n",
        "print(rocks[\"igneous\"][1])\n",
        "print(rock_dict[\"granite\"])\n",
        "print(rock_dict[\"granite\"][\"composition\"])\n",
        "print(rock_dict[\"granite\"][\"composition\"][\"quartz\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxxkP3Z3z7rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can also expand dictionaries using indexing assignment:\n",
        "De2En[\"Semmel\"] = \"Bread roll\"\n",
        "print(De2En)\n",
        "\n",
        "rocks[\"metamorphic\"] = [\"Gneiss, Schist\"]\n",
        "print(rocks)\n",
        "\n",
        "# And you can use methods on the objects indexed:\n",
        "rocks[\"igneous\"].append(\"Gabbro\")\n",
        "print(rocks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tktNc5E0PLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoBZl5Rjoiuq",
        "colab_type": "text"
      },
      "source": [
        "# Section 2.2 - Numpy part 1\n",
        "Last week we used the popular python library Pandas, but didn't introduce it formally.\n",
        "This week we will also be using a popular libary called Numpy.\n",
        "Pandas is built upon Numpy, and they work well together.\n",
        "Pandas is good at data handling, manipulation and analysis, while Numpy is the basis of numerical operations and processing.\n",
        "See more here:\n",
        "* https://pandas.pydata.org/\n",
        "* https://numpy.org/\n",
        "\n",
        "We will use both Pandas and Numpy throughout the course. Together (along with matplotlib), they are the basis of Data Science in python.\n",
        "\n",
        "Numpy is based around multi-dimensional arrays (of data), and allows efficient indexing, operations and aggregation of said arrays.\n",
        "For those not familiar with multi-dimensional arrays (also called nd-arrays), imagine an excel spreadsheet as a 2 dimensional table/array with rows and columns, but that you can have as many dimensions as you like.\n",
        "\n",
        "As an example, in satellite remote sensing, it is typical to have a time-series of many multi-band (e.g. red, green, blue, infra-red) images. Therefore, you might have an array of 4 dimensions: [pixel rows, pixel columns, time, band]. So for each x-y pixel, at each point in time, you have a value for each band.\n",
        "\n",
        "In the following section, we will create arrays, learn how to do simple operations on them and perform basic aggregations. In the following section, we will explore Numpy's powerful indexing system.\n",
        "\n",
        "The website Datacamp.com provides an excellent Numpy \"cheat-sheet\". It is highly recommended to keep it handy when working with Numpy, and going through it in your own time.\n",
        "https://www.datacamp.com/community/blog/python-numpy-cheat-sheet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nxjB2a5l7SQ",
        "colab_type": "text"
      },
      "source": [
        "## 2.2.1 - Creating Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAPAdQKrr9V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we cover simple ways to create numpy arrays.\n",
        "# We will cover loading and importing data, e.g. from pandas later.\n",
        "\n",
        "# The simplest way to create an array is from a list\n",
        "array = np.array([1,2,3])\n",
        "print(array)\n",
        "\n",
        "# Or with nested lists for multiple dimensions\n",
        "array_2d = np.array([[1,2,3],[4,5,6]])\n",
        "print(array_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5vUGGJs81eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy provides some functions to create arrays by shape:\n",
        "# make a 1d array of 5 zeros\n",
        "array_zeros = np.zeros(5) \n",
        "print(array_zeros)\n",
        "\n",
        "# Make a 2d array of 1s\n",
        "array_ones = np.ones((2,5))\n",
        "print(array_ones)\n",
        "\n",
        "# numpy arrays have an attribute shape:\n",
        "print(\"array_zeros size:\", array_zeros.shape)\n",
        "print(\"array_ones size:\", array_ones.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl17kKwM9oAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an array of consecutive integers in a range using np.arange\n",
        "arange_1 = np.arange(15,25)\n",
        "print(arange_1)\n",
        "\n",
        "# Use arange to create larger steps\n",
        "arange_2 = np.arange(15,25,2)\n",
        "print(arange_2)\n",
        "\n",
        "# If one needs a standard python list in this style:\n",
        "print(range(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aW9N4XQ-Pfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create array across range by number of intermediate steps, rather than the step itself\n",
        "linspace_1 = np.linspace(0,4,17)\n",
        "print(linspace_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbu5wLYikml7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrays of random numbers can be produced with np.random.random_sample np.random.standard_normal\n",
        "uni_random = np.random.random_sample(10)\n",
        "print(uni_random)\n",
        "\n",
        "np.random.standard_normal()\n",
        "norm_random = np.random.standard_normal(10)\n",
        "print(norm_random)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi7UEkuVl443",
        "colab_type": "text"
      },
      "source": [
        "## 2.2.2 - Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QudTWd5mJ8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python lets us do operations on integers and floats\n",
        "print(1+2)\n",
        "print(2*3)\n",
        "print(2.5*5)\n",
        "print(2**6)\n",
        "print(64/4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXu_TJ9wngK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# But on lists, these operators do other things:\n",
        "print([1,2,3] + [4]) # List concatenation\n",
        "print([1,2,3] * 3) # List duplication\n",
        "# Operators like / and - do not work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImMqH2EfyJU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Operators can be applied to numpy arrays in an intuitive way:\n",
        "# Operators between a numpy array and a single int or float apply the operation to all elements in the array:\n",
        "a = np.ones(5)\n",
        "b = np.arange(5)\n",
        "\n",
        "print(\"a:\",a)\n",
        "print(\"a + 1:\",a + 1)\n",
        "print(\"a - 1:\",a - 1)\n",
        "print(\"a * 2:\",a * 2)\n",
        "print(\"a / 2:\",a / 2)\n",
        "\n",
        "print(\"b * 2:\", b * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHDF6VEez_IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Operations between arrays of the same shape result are element-wise:\n",
        "print(\"b:\",b)\n",
        "print(\"b * b:\", b * b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoHf9v3o3M2T",
        "colab_type": "text"
      },
      "source": [
        "## 2.2.3 - Aggregations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua1XUbid3aau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QGNl98ajWwh",
        "colab_type": "text"
      },
      "source": [
        "# Section 3 - Numpy Excercise 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8AAsIn80WeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the following sequences as numpy arrays:\n",
        "# 1. [3, 6, 9, 12, ...., 99]\n",
        "# 2. [15, 15, 15, 15, 15, 15]\n",
        "# 3. [0, 0.5, 1, 1.5, ...., 100]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRMHO66N3HNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the following arrays:\n",
        "# 1. 1d array of size 100 with random decimal numbers between 1 and 100\n",
        "# 2. 1d array of size 50 with random integers between 25 and 75\n",
        "# 3. 1d array of size 100 with normal (gaussian) distributed numbers with a mean of 5 and a standard deviation of 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9WhCxd3HFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPg8rlxc7sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenges\n",
        "# 1. [0,1,0,2,0,4,0,8,0,16,0,32,0,64,.....65536]\n",
        "#   Note, this can be done in many different ways, including with other numpy functions\n",
        "#   and using numpy indexing, but it is possible to do with only the functions described above.\n",
        "# 2. An array representing the sum of rolling a pair of 6 sided dice 1000 times (if your game of monopoly overruns more than usual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaFGg2jdxEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(2 ** np.arange(-0.5,50.5,0.5)) * np.array([0,1]*51)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAgJFIO5r9o2",
        "colab_type": "text"
      },
      "source": [
        "# Section 3 - Numpy 2\n",
        "\n",
        "Indexing, simple broadcasting and booleans (first)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jLSIBPHsXyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bK77j8nC_cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7n8GC7ssYOZ",
        "colab_type": "text"
      },
      "source": [
        "# Section 4 - LA-ICPMS data reduction excercise\n",
        "*Write this, then check all requirements are fulfilled above*\n",
        "\n",
        "In the geosciences, we often have raw measurement data from an analytical machine, and need to convert or \"reduce\" that data to make it useful for further analysis and interpretation. A very common example is conversion of mass spectrometer (or similar) raw count data to composition data, such as weight percentage or ppm of the analysis material. In many cases there are specific software packages to perform this data reduction without needing to do any coding, but frequently the underlying methodology is not complex and could be easily done in python. As an example, in this excercise we will convert raw Laser Ablation - ICP Mass Spectrometer (LA-ICPMS) data to mass fraction of the sample material.\n",
        "\n",
        "The following paper explains LA-ICPMS, typical data reduction proceedures and software packages:\n",
        "https://www.sciencedirect.com/science/article/abs/pii/S0009254118305461?via%3Dihub\n",
        "\n",
        "Using python, we will perform steps 2 to 5 of the \"Basic Processing\" in section 2.1 of that paper.\n",
        "\n",
        "**Note: Each field (within and beyond the geosciences) has its own literature about data reduction and processing. You should consult authoritative sources when doing this work to avoid methodological errors. This excercise is intended to demonstrate that the mathematical and programming required is easily achievable with only basic python knowledge.***\n",
        "\n",
        "**Data Reduction Steps**:\n",
        "* 1. Load the data\n",
        "* 2. Identification of background, samples and standards in the raw data\n",
        "* 3. Apply background correction\n",
        "* 4. Standardise data\n",
        "* 5. Calibrate data to standards\n",
        "* 6. Calculate the mass fraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWF3i3qLh9l9",
        "colab_type": "text"
      },
      "source": [
        "## 2.4.1 - Load data\n",
        "\n",
        "The example data we will use is from the testing datasets for a python tool for LA-ICPMS data reduction:\n",
        "(https://github.com/oscarbranson/latools)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r42R3M1-q1Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data from here as a pandas data frame:\n",
        "# https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/laicpms_sample.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbE_pP54tKFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create:\n",
        "# 1. a 1d numpy array of the \"Time\" column\n",
        "# 2. a 2d numpy array of the element count columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daaHvUUWfj5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ANSWERS\n",
        "data_pd = pd.read_csv(\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/laicpms_sample.csv\", header=1)\n",
        "data = data_pd.to_numpy()\n",
        "time = data[:,0]\n",
        "raw_te = data[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fGsi-3Cutsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a/some plots of the data to get an overview"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1dkIRfdpcy",
        "colab_type": "text"
      },
      "source": [
        "## 2.4.2 - Identify background, samples and standards\n",
        "\n",
        "When you plot the data, you will see several periods where the counts (for any element) are well above 0. The first 3 of these sections are standards, the last 4 are samples. The intermediate parts are background.\n",
        "\n",
        "We need to identify the time intervals corresponding to samples, sections and background for the following analyses. We will do this by identifying the start and end times/positions (here, position is measured in time) for each relevant section. We then create a boolean index array for each.\n",
        "\n",
        "It is recommended to work together with your classmates to complete this task by sharing the start and end positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J80xY262vcRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find out and record the start and end positions of at least 2 background sections\n",
        "# Record them in a list containing dictionaries with the following format:\n",
        "# [{\"start\": <position in seconds>, \"end\": <position in seconds>}\n",
        "#  {\"start\": <>, \"end\": <>},\n",
        "#   .....]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfdFI4eVxHWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the same for all the sample sections, and separately for all the standards sections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBtZ16KdsX20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a boolean index array for each of background, samples and standards.\n",
        "# Each should be same shape as the time array (use the .shape method to check).\n",
        "# hint: use np.logical_and to create a boolean index for each section,\n",
        "#       then combine the results with np.any. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9USLlPkevuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ANSWERS\n",
        "bg_loc = [{\"start\": 0, \"end\": 25},\n",
        "          {\"start\": 491, \"end\": 498}]\n",
        "stand_loc = [{\"start\": 27, \"end\": 82},\n",
        "            {\"start\": 105, \"end\": 160},\n",
        "            {\"start\": 184, \"end\": 220},\n",
        "            ]\n",
        "samp_loc = [{\"start\": 269, \"end\": 340 },\n",
        "            {\"start\": 363, \"end\": 389},\n",
        "            {\"start\": 409, \"end\": 433},\n",
        "            {\"start\": 453, \"end\": 487}]\n",
        "\n",
        "bg_idx = np.any([np.logical_and(time > bg_loc[0][\"start\"], time < bg_loc[0][\"end\"]),\n",
        "                 np.logical_and(time > bg_loc[1][\"start\"], time < bg_loc[1][\"end\"])],\n",
        "                axis=0)\n",
        "\n",
        "stand_idx = np.any([np.logical_and(time > stand_loc[0][\"start\"], time < stand_loc[0][\"end\"]),\n",
        "                 np.logical_and(time > stand_loc[1][\"start\"], time < stand_loc[1][\"end\"]),\n",
        "                 np.logical_and(time > stand_loc[2][\"start\"], time < stand_loc[2][\"end\"])],\n",
        "                axis=0)\n",
        "\n",
        "samp_idx = np.any([np.logical_and(time > samp_loc[0][\"start\"], time < samp_loc[0][\"end\"]),\n",
        "                 np.logical_and(time > samp_loc[1][\"start\"], time < samp_loc[1][\"end\"]),\n",
        "                 np.logical_and(time > samp_loc[2][\"start\"], time < samp_loc[2][\"end\"])],\n",
        "                axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wlqUAYxsGP",
        "colab_type": "text"
      },
      "source": [
        "## 2.4.3 - Apply background correction\n",
        "The background counts should be removed from the rest of the signal for each element.\n",
        "\n",
        "We therefore take the average counts during the background periods for each element and subtract these values from the element arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYRHa3cjzD5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an array of the average (mean) counts for each element during the background sections.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAM3WonJzMs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subtract the per-element backgrounds from the entire dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i40PWnQkzNAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ANSWER\n",
        "bg_vals = np.mean(raw_te[bg_idx], axis=0)\n",
        "bg_corr = raw_te - bg_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLhnTepK4NW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUTb69tF4WUj",
        "colab_type": "text"
      },
      "source": [
        "##2.4.4 - Standardize data\n",
        "In LA-ICPMS analysis, the amount of analyte which is measured depends on how much is ablated by the laser, which in turn depends on the material properties of the sample (known as matrix effects). To remove matrix effects and other spurious features, we can standardize the data to an element which we expect to be present at a constant concentration. For carbonates, an isotope of Ca is often used and is known as the internal standard.\n",
        "\n",
        "Standardization in this case means that we convert all other element data to count ratios of that element vs Ca44."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boYpKYru5nL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all data into ratios to Ca44 - i.e. divide all element counts by Ca44 counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUQ0HEMo5m2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ANSWER\n",
        "castd_te = bg_corr / bg_corr[:,4:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhD4bRcl1WtV",
        "colab_type": "text"
      },
      "source": [
        "##2.4.5 - Calibrate data\n",
        "Next we calibrate the count ratios to composition ratios. We do this using the measured standards of known composition.\n",
        "\n",
        "Preparation of the standard composition in terms of count ratio is beyond the scope of this excercise, so the required data is provided ready-to-use. In this case, we will only use one of the standards, but more complex methods exist to simultaneously calibrate using multiple standards and to thereby improve estimation of the measurement uncertainty.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8UR7Qk_289r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the standard composition from here:\n",
        "# https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/laicpms_standard.csv\n",
        "# Convert the dataframe to a numpy array and check its shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byAhAfzA1ZLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The calibration data refers only to the first measured standard.\n",
        "# Create an boolean index array for this standard.\n",
        "# Then calculate the mean values per element for the standard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnukHuAu2Siy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the conversion ratio by dividing calibration data by the measured (standardized) standard data\n",
        "# Apply the conversion ratio by dividing the standardized element data by the calibration\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR5cmfw5AKjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all data except the samples\n",
        "# Assign everything else to np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Efr6klNAejq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make some plots to visualise the output.\n",
        "# Optionally you can convert the calibrated data back to a pandas DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yx8D6Ro1XQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ANSWER\n",
        "std_dat = pd.read_csv(r\"https://raw.githubusercontent.com/ds4geo/ds4geo/master/data/timeseries/laicpms_standard.csv\",sep=\",\").to_numpy()\n",
        "#cali_te = castd_te / std_dat\n",
        "stand_1_idx = np.logical_and(time > stand_loc[0][\"start\"], time < stand_loc[0][\"end\"])\n",
        "stand_comp = np.mean(castd_te[stand_1_idx,:], axis=0)\n",
        "calibr = std_dat / stand_comp\n",
        "calibrated = castd_te / calibr\n",
        "calibrated[~samp_idx] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwWCjU-p2ZQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c,l in enumerate(data_pd.columns[1:]):\n",
        "  plt.plot(time,calibrated[:,c], label=l)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-znfd4nSDIKc",
        "colab_type": "text"
      },
      "source": [
        "##2.4.6 Calibrate mass fraction\n",
        "We standardized our data to an internal standard of constant concentration (i.e. a ratio of Ca44). However, if we want to calculate the mass fraction, we need to convert our data back from that ratio to the mass fraction. To do this, we need to know the concentration of the internal standard in the material. This needs to be separately measured or assumed.\n",
        "\n",
        "Here we will make an assumption."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7cZs4RMEp19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estimate mass fraction of Ca44 in sample (a foram)\n",
        "# Assume the foram is entirely composed of CaCO3\n",
        "# 1. Calculate the weight fraction of Ca in CaCO3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CChaCnxY-Z6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}